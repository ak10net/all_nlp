{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "portuguese-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aerial-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/yelp_labelled.txt', names=['sentence', 'label'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "engaging-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['sentence'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "stretch-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-sending",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "descending-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "train_X = vectorizer.fit_transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fewer-benefit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_X, train_y)\n",
    "score = classifier.score(test_X, test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-webster",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "built-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "arctic-burner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                17250     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 17,261\n",
      "Trainable params: 17,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "stuffed-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)\n",
    "\n",
    "train_X = convert_sparse_matrix_to_sparse_tensor(train_X)\n",
    "test_X = convert_sparse_matrix_to_sparse_tensor(test_X)\n",
    "train_X = tf.sparse.reorder(train_X)\n",
    "test_X  = tf.sparse.reorder(test_X)\n",
    "train_y = tf.convert_to_tensor(train_y)\n",
    "test_y = tf.convert_to_tensor(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "entire-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_y,\n",
    "                   epochs=50,\n",
    "                   verbose=False,\n",
    "                   validation_data=(test_X, test_y),\n",
    "                   batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "electronic-holmes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(train_X, train_y, verbose=False)\n",
    "print(f'Training accuracy {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "union-sunrise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.7839999794960022\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_X, test_y, verbose=False)\n",
    "print(f'Training accuracy {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-cinema",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "sunset-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "relevant-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(train_X)\n",
    "X_test = tokenizer.texts_to_sequences(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "assumed-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "shaped-labor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not tasty and the texture was just nasty.\n",
      "[3, 105, 349, 549, 1, 158, 29, 132, 876, 124, 9, 4, 5, 400, 171]\n"
     ]
    }
   ],
   "source": [
    "print(X[2])\n",
    "print(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "deadly-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "finished-david",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3, 105, 349, 549,   1, 158,  29, 132, 876, 124,   9,   4,   5,\n",
       "       400, 171,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "absent-pocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 50)           103600    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                50010     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 153,621\n",
      "Trainable params: 153,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size,\n",
    "         output_dim=embedding_dim,\n",
    "         input_length=maxlen))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "elegant-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, train_y,\n",
    "                    epochs=20,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test, test_y),\n",
    "                    batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "funny-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.7920\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, train_y, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, test_y, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-sacrifice",
   "metadata": {},
   "source": [
    "#### with max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "surface-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 50)           103600    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 104,121\n",
      "Trainable params: 104,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size,\n",
    "         output_dim=embedding_dim,\n",
    "         input_length=maxlen))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "piano-restriction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.8360\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, train_y,\n",
    "                    epochs=20,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test, test_y),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, train_y, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, test_y, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-walker",
   "metadata": {},
   "source": [
    "### Convolution NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dependent-begin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          207200    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 96, 128)           64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 272,629\n",
      "Trainable params: 272,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim,input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "checked-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.8080\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, train_y,\n",
    "                    epochs=10,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test, test_y),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, train_y, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, test_y, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-rouge",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "disabled-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_filters, kernel_size, vocab_size, embedding_dim, maxlen):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "    model.add(layers.Conv1D(num_filters, kernel_size, activation='relu'))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "automatic-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(num_filters=[32, 64, 128],\n",
    "                  kernel_size=[3, 5, 7],\n",
    "                  vocab_size=[5000], \n",
    "                  embedding_dim=[50],\n",
    "                  maxlen=[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "available-jersey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model,\n",
    "                       epochs=epochs,\n",
    "                       batch_size=10,\n",
    "                       verbose=False)\n",
    "grid = RandomizedSearchCV(estimator=model, \n",
    "                    param_distributions=param_grid,\n",
    "                        cv=4,\n",
    "                         verbose=1, n_iter=5)\n",
    "grid_result = grid.fit(X_train, train_y)\n",
    "test_accuracy = grid.score(X_test, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "sunrise-accent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7906758338212967"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "loaded-bread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 5000,\n",
       " 'num_filters': 32,\n",
       " 'maxlen': 100,\n",
       " 'kernel_size': 3,\n",
       " 'embedding_dim': 50}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "plain-stress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8240000009536743"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-maple",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
